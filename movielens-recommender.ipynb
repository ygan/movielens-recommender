{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommend System Based on MovieLens 20M Dataset\n",
    "### Note:\n",
    "This code is just an exercise.  \n",
    "Due to the shortage of time, there are many shortcomings in it.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "DATA_SET_NAME = 'ml-20m'\n",
    "DATA_PATH = './data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download MovieLens 20M Dataset\n",
    "The data will be download to this path: \"**./data**\" and unzip automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading ml-20m.zip: 199MB [02:00, 1.65MB/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    \"\"\"\n",
    "    Handle Progress Bar while Downloading\n",
    "    \"\"\"\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        \"\"\"\n",
    "        A hook function that will be called once on establishment of the network connection and\n",
    "        once after each block read thereafter.\n",
    "        \"\"\"\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "        \n",
    "def download_extract():\n",
    "    \"\"\"\n",
    "    Download and extract database\n",
    "    \"\"\"\n",
    "    url = 'http://files.grouplens.org/datasets/movielens/' + DATA_SET_NAME + '.zip'\n",
    "    \n",
    "    if not os.path.exists(DATA_PATH):\n",
    "        os.makedirs(DATA_PATH)\n",
    "    \n",
    "    file_path = os.path.join(DATA_PATH, DATA_SET_NAME + '.zip')\n",
    "    \n",
    "    # download data:\n",
    "    if not os.path.exists(file_path):\n",
    "        with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Downloading ml-20m.zip') as pbar:\n",
    "            urlretrieve(\n",
    "                url,\n",
    "                file_path,\n",
    "                pbar.hook)\n",
    "    else:\n",
    "        return\n",
    "    \n",
    "    print('Extracting data...')\n",
    "    with zipfile.ZipFile(file_path) as zf:\n",
    "        zf.extractall(DATA_PATH)\n",
    "\n",
    "    print('Done.')\n",
    "\n",
    "#-------------------------------------------------------\n",
    "download_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Load and Preview Data\n",
    "&ensp;&ensp;Load data and preview the data at the beginning.\n",
    "There are six csv files in the dataset: `links.csv`, `movies.csv`, `ratings.csv`, `tags.csv`, `genome-tags.csv`, `genome-scores.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movies.csv: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('movies.csv: ')\n",
    "movies = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'movies.csv'),index_col=None)\n",
    "movies.describe()\n",
    "movies.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratings.csv: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112486027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1        2     3.5  1112486027\n",
       "1       1       29     3.5  1112484676\n",
       "2       1       32     3.5  1112484819\n",
       "3       1       47     3.5  1112484727\n",
       "4       1       50     3.5  1112484580"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('ratings.csv: ')\n",
    "ratings = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'ratings.csv'),index_col=None)\n",
    "ratings.describe()\n",
    "ratings.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tags.csv: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4141</td>\n",
       "      <td>Mark Waters</td>\n",
       "      <td>1240597180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65</td>\n",
       "      <td>208</td>\n",
       "      <td>dark hero</td>\n",
       "      <td>1368150078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65</td>\n",
       "      <td>353</td>\n",
       "      <td>dark hero</td>\n",
       "      <td>1368150079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>521</td>\n",
       "      <td>noir thriller</td>\n",
       "      <td>1368149983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65</td>\n",
       "      <td>592</td>\n",
       "      <td>dark hero</td>\n",
       "      <td>1368150078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId            tag   timestamp\n",
       "0      18     4141    Mark Waters  1240597180\n",
       "1      65      208      dark hero  1368150078\n",
       "2      65      353      dark hero  1368150079\n",
       "3      65      521  noir thriller  1368149983\n",
       "4      65      592      dark hero  1368150078"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('tags.csv: ')\n",
    "tags = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'tags.csv'),index_col=None)\n",
    "tags.describe()\n",
    "tags.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genome-tags.csv: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tagId</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>007 (series)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>18th century</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1920s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1930s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tagId           tag\n",
       "0      1           007\n",
       "1      2  007 (series)\n",
       "2      3  18th century\n",
       "3      4         1920s\n",
       "4      5         1930s"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('genome-tags.csv: ')\n",
    "genome_tags = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'genome-tags.csv'),index_col=None)\n",
    "genome_tags.describe()\n",
    "genome_tags.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genome-scores.csv: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>tagId</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.02500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.05775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.09675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.14675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId  tagId  relevance\n",
       "0        1      1    0.02500\n",
       "1        1      2    0.02500\n",
       "2        1      3    0.05775\n",
       "3        1      4    0.09675\n",
       "4        1      5    0.14675"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('genome-scores.csv: ')\n",
    "genome_scores = pd.read_csv(os.path.join(DATA_PATH, DATA_SET_NAME,'genome-scores.csv'),index_col=None)\n",
    "genome_scores.describe()\n",
    "genome_scores.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Simple Statistics\n",
    "Do simple Statistics and it will help us understand the data better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of movies: 27278\n",
      "The number of ratings: 20000263\n",
      "\n",
      "min value of rating: 0.5\n",
      "max value of rating: 5.0\n",
      "\n",
      "The number of user in ratings.csv: 138493\n",
      "The minimum number of ratings per user in ratings.csv: 20\n",
      "The maximun number of ratings per user in ratings.csv: 9254\n",
      "\n",
      "The number of movies in ratings.csv: 26744\n",
      "The minimum number of ratings per movie in ratings.csv: 1\n",
      "The maximun number of ratings per movie in ratings.csv: 67310\n"
     ]
    }
   ],
   "source": [
    "print('The number of movies: {}'.format(movies.count()['movieId']))\n",
    "print('The number of ratings: {}'.format(ratings.count()['movieId']))\n",
    "\n",
    "print('')\n",
    "print('min value of rating: {}'.format(ratings['rating'].min()))\n",
    "print('max value of rating: {}'.format(ratings['rating'].max()))\n",
    "\n",
    "print('')\n",
    "ra = ratings.groupby(ratings['userId']).count()\n",
    "print('The number of user in ratings.csv: {}'.format(ra.count()[0]))\n",
    "print('The minimum number of ratings per user in ratings.csv: {}'.format(ra['movieId'].min()))\n",
    "print('The maximun number of ratings per user in ratings.csv: {}'.format(ra['movieId'].max()))\n",
    "\n",
    "print('')\n",
    "ra = ratings.groupby(ratings['movieId']).count()\n",
    "print('The number of movies in ratings.csv: {}'.format(ra.count()[0]))\n",
    "print('The minimum number of ratings per movie in ratings.csv: {}'.format(ra['userId'].min()))\n",
    "print('The maximun number of ratings per movie in ratings.csv: {}'.format(ra['userId'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tags in tags.csv: 465564\n",
      "The number of tags in genome-tags.csv: 1128\n",
      "\n",
      "The number of user in tags.csv: 7801\n",
      "The minimum number of tags per user in tags.csv: 1\n",
      "The maximun number of tags per user in tags.csv: 20356\n",
      "\n",
      "The number of movies in tags.csv: 19545\n",
      "The minimum number of tags per movie in tags.csv: 1\n",
      "The maximun number of tags per movie in tags.csv: 1994\n",
      "\n",
      "The number of tags in tags.csv but not in genome-tags.csv: 247993\n"
     ]
    }
   ],
   "source": [
    "print('The number of tags in tags.csv: {}'.format(tags.count()['userId']))\n",
    "print('The number of tags in genome-tags.csv: {}'.format(genome_tags.count()['tagId']))\n",
    "\n",
    "print('')\n",
    "ra = tags.groupby(tags['userId']).count()\n",
    "print('The number of user in tags.csv: {}'.format(ra.count()[0]))\n",
    "print('The minimum number of tags per user in tags.csv: {}'.format(ra['movieId'].min()))\n",
    "print('The maximun number of tags per user in tags.csv: {}'.format(ra['movieId'].max()))\n",
    "\n",
    "print('')\n",
    "ra = tags.groupby(tags['movieId']).count()\n",
    "print('The number of movies in tags.csv: {}'.format(ra.count()[0]))\n",
    "print('The minimum number of tags per movie in tags.csv: {}'.format(ra['userId'].min()))\n",
    "print('The maximun number of tags per movie in tags.csv: {}'.format(ra['userId'].max()))\n",
    "\n",
    "print('')\n",
    "tags_mer = pd.merge(tags, genome_tags, how='left', left_on='tag', right_on='tag')\n",
    "print('The number of tags in tags.csv but not in genome-tags.csv: {}'.format(tags_mer[(tags_mer['tagId'].isnull())].count()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of genome_scores.csv: 11709768\n",
      "max value of relevance from genome_scores.csv: 1.0\n",
      "min value of relevance from genome_scores.csv: 0.00024999999999997247\n",
      "\n",
      "The number of movies in genome_scores.csv: 10381\n",
      "The minimum number of tags per movie in genome_scores.csv: 1128\n",
      "The maximun number of tags per movie in genome_scores.csv: 1128\n"
     ]
    }
   ],
   "source": [
    "print('The length of genome_scores.csv: {}'.format(genome_scores.count()['movieId']))\n",
    "print('max value of relevance from genome_scores.csv: {}'.format(genome_scores['relevance'].max()))\n",
    "print('min value of relevance from genome_scores.csv: {}'.format(genome_scores['relevance'].min()))\n",
    "\n",
    "print('')\n",
    "ra = genome_scores.groupby(genome_scores['movieId']).count()\n",
    "print('The number of movies in genome_scores.csv: {}'.format(ra.count()[0]))\n",
    "print('The minimum number of tags per movie in genome_scores.csv: {}'.format(ra['tagId'].min()))\n",
    "print('The maximun number of tags per movie in genome_scores.csv: {}'.format(ra['tagId'].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies in both genome_scores.csv and ratings.csv: 10370. Take up 53.0% of ratings.csv\n",
      "Number of ratings where its movieId in genome_scores.csv: 19800443. Take up 99.0% of ratings.csv\n",
      "\n",
      "138493 users rate the movies appearing in both genome_scores.csv and ratings.csv. Take up 100.0% of ratings.csv\n",
      "Minimum number of ratings per user for the movies appearing in both genome_scores.csv and ratings.csv: 13\n"
     ]
    }
   ],
   "source": [
    "# Analysis the relevant data of movies in both genome_scores.csv and ratings.csv:\n",
    "\n",
    "genome_scores_group = genome_scores.groupby(genome_scores['movieId']).mean()\n",
    "ratings_group = ratings.groupby(ratings['movieId']).mean()\n",
    "rat_ge_merge = pd.merge(ratings_group, genome_scores_group, how='inner', left_on='movieId', right_on='movieId')\n",
    "number = rat_mer.count()[0]\n",
    "print('Number of movies in both genome_scores.csv and ratings.csv: {}. Take up {}% of ratings.csv'\\\n",
    "      .format(number, round(number/19545*100)))\n",
    "\n",
    "ratings_genome_merge = pd.merge(ratings, genome_scores_group, how='inner', left_on='movieId', right_on='movieId')\n",
    "number = ratings_genome_merge.count()[0]\n",
    "print('Number of ratings where its movieId in genome_scores.csv: {}. Take up {}% of ratings.csv'\\\n",
    "      .format(number, round(number/20000263*100)))\n",
    "\n",
    "print('')\n",
    "ra = ratings_genome_merge.groupby(ratings_genome_merge['userId']).count()\n",
    "number = ra.count()[0]\n",
    "print('{} users rate the movies appearing in both genome_scores.csv and ratings.csv. Take up {}% of ratings.csv'\\\n",
    "      .format(number, round(number/138493*100)))\n",
    "print('Minimum number of ratings per user for the movies appearing in both genome_scores.csv and ratings.csv: {}'.format(ra['movieId'].min()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Assumption and Machine Learning Model\n",
    "## 4.1 Assumption\n",
    "To simplify the problem, the following assumptions are proposed:  \n",
    "1. The tags in `genome-tags.csv` are the complete set of tags vector spaces. Other tags not in `genome-tags.csv`  are linear combinations of tags in `genome-tags.csv`.  \n",
    "2. The feature of movies can be perfectly represent by tags in `genome-tags.csv` such as relevance vector in `genome_scores.csv`.  \n",
    "The relevance vector in `genome_scores.csv` is correct and can represent the feature of movies.  \n",
    "3. Ignore the quality of movies.  \n",
    "4. We cannot get other movies information outside the dataset. So we don't use `links.csv`.\n",
    "5. Release time of movies does not affect.  \n",
    "6. Timestamp in `ratings.csv: ` and `tags.csv` does not affect.  \n",
    "\n",
    "\n",
    "## 4.2 Definition Problem\n",
    "\n",
    "&ensp;&ensp;I choose 19800443 ratings data to build a model to verify our assumption. These 19800443 ratings contain 10370 different movies and 138493 different users. Every movie have a unique relevance vector.  \n",
    "&ensp;&ensp;So the problem based on these data is: give the user id and movie id, predict the rating of the movie by this user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Create Training Data\n",
    "&ensp;&ensp;Split 19800443 rating data (where its movieId in genome_scores.csv) to training set (80%) and test set (20%). We can see the test data include 99.86% users. If you already have the preprocessed data, you can load it from the last code cell in the section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data (You should run last code cell to get 'ratings_genome_merge')\n",
    "# The first column of features is userId, the next is movieId.\n",
    "# The only one column of target is rating.\n",
    "\n",
    "remove_fields = ['timestamp','tagId','relevance','rating']\n",
    "target = ratings_genome_merge['rating']\n",
    "feature = ratings_genome_merge.drop(remove_fields, axis=1)\n",
    "features = feature.values\n",
    "target = target.values\n",
    "\n",
    "genome_scores_dict = {}\n",
    "for i in range(10381):\n",
    "    m_id = -1\n",
    "    vec = []\n",
    "    for j in range(1128):\n",
    "        index = j + i * 1128\n",
    "        if m_id < 0:\n",
    "            m_id = genome_scores['movieId'][index]\n",
    "        assert genome_scores['movieId'][index] == m_id\n",
    "        assert genome_scores['tagId'][index] == j + 1\n",
    "        vec.append(genome_scores['relevance'][index])\n",
    "    genome_scores_dict[str(m_id)] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.86% users in test set (138294 users)\n",
      "100.0% users in training set (138493 users)\n"
     ]
    }
   ],
   "source": [
    "# Actually, using train_test_split in here is not best. \n",
    "# The better method should split the data according the userId, which make sure every user is in the test set.\n",
    "# But here, let us make it easier and quickly ( We have already include 99.86% users).\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_features,test_features, train_target, test_target = train_test_split(features,  \n",
    "                                                           target,  \n",
    "                                                           test_size = 0.2,  \n",
    "                                                           random_state = 0)\n",
    "\n",
    "dict_t = {}\n",
    "dict_t['userId'] = test_features[:,0]\n",
    "dict_t['movieId'] = test_features[:,1]\n",
    "pd_data = pd.DataFrame.from_dict(dict_t)\n",
    "user_test = pd_data.groupby(pd_data['userId']).count().count()[0]\n",
    "\n",
    "print('{}% users in test set ({} users)'.format(round(user_test/138493*100, 2), user_test ))\n",
    "\n",
    "dict_t = {}\n",
    "dict_t['userId'] = train_features[:,0]\n",
    "dict_t['movieId'] = train_features[:,1]\n",
    "pd_data = pd.DataFrame.from_dict(dict_t)\n",
    "user_train = pd_data.groupby(pd_data['userId']).count().count()[0]\n",
    "\n",
    "print('{}% users in training set ({} users)'.format(round(user_train/138493*100, 2), user_train ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocess data to './data/verify_assumption.data'\n",
    "pickle.dump((train_features, test_features, train_target, test_target, genome_scores_dict), open('./data/verify_assumption.data', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocess data from './data/verify_assumption.data'\n",
    "train_features, test_features, train_target, test_target, genome_scores_dict = pickle.load(open('./data/verify_assumption.data', mode='rb'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Build Model\n",
    "&ensp;&ensp;If relevance vector in `genome_scores.csv` can represent the movies, we can use it to build a model that predict the rating by the users. And this model shouldn't be much worse than others. Here, give a simple machine learning model:\n",
    "<img src=\"Img/model.png\"  height=\"320\" width=\"250\">\n",
    "### Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 768  # batch size \n",
    "lr = 1e-3         # learning rate\n",
    "feature_dim = 512 # Dimension of movie or user feature vector\n",
    "Epoch = 6         # train epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Verify_Assumption_Model(nn.Module):\n",
    "    \"\"\"The whole model\"\"\"\n",
    "    def __init__(self):\n",
    "        super(Verify_Assumption_Model, self).__init__()\n",
    "        self.emb_user = nn.Embedding(138493 + 1, 512, # use ratings['userId'].max()+1 instead of 138493+1 is better\n",
    "                            padding_idx=0)\n",
    "        \n",
    "        self.movie_transfrom = nn.Sequential(\n",
    "            nn.Linear(1128, 512),\n",
    "            nn.Tanh(), # activation function can not be the final layer of Sequential. But it can be the first one.\n",
    "            nn.Linear(512, 512)\n",
    "        )\n",
    "    \n",
    "    def forward(self, userId, movieVector):\n",
    "        v_user  = self.emb_user(userId)\n",
    "        v_movie = self.movie_transfrom(movieVector)\n",
    "        v_user.unsqueeze_(1)\n",
    "        v_movie.unsqueeze_(2)\n",
    "        return torch.bmm(v_user,v_movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yj/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/_reduction.py:49: UserWarning: size_average and reduce args will be deprecated, please use reduction='none' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch 383232/15840354   train_loss = 12942.916\n",
      "Epoch   0 Batch 767232/15840354   train_loss = 7903.710\n",
      "Epoch   0 Batch 1151232/15840354   train_loss = 5572.569\n",
      "Epoch   0 Batch 1535232/15840354   train_loss = 2904.491\n",
      "Epoch   0 Batch 1919232/15840354   train_loss = 2354.743\n",
      "Epoch   0 Batch 2303232/15840354   train_loss = 1838.493\n",
      "Epoch   0 Batch 2687232/15840354   train_loss = 1632.287\n",
      "Epoch   0 Batch 3071232/15840354   train_loss = 1319.965\n",
      "Epoch   0 Batch 3455232/15840354   train_loss = 1239.193\n",
      "Epoch   0 Batch 3839232/15840354   train_loss = 1260.753\n",
      "Epoch   0 Batch 4223232/15840354   train_loss = 1390.432\n",
      "Epoch   0 Batch 4607232/15840354   train_loss = 1465.220\n",
      "Epoch   0 Batch 4991232/15840354   train_loss = 1204.264\n",
      "Epoch   0 Batch 5375232/15840354   train_loss = 1253.578\n",
      "Epoch   0 Batch 5759232/15840354   train_loss = 1196.916\n",
      "Epoch   0 Batch 6143232/15840354   train_loss = 1118.606\n",
      "Epoch   0 Batch 6527232/15840354   train_loss = 1142.375\n",
      "Epoch   0 Batch 6911232/15840354   train_loss = 1049.916\n",
      "Epoch   0 Batch 7295232/15840354   train_loss = 1144.789\n",
      "Epoch   0 Batch 7679232/15840354   train_loss = 1226.962\n",
      "Epoch   0 Batch 8063232/15840354   train_loss = 1130.071\n",
      "Epoch   0 Batch 8447232/15840354   train_loss = 993.428\n",
      "Epoch   0 Batch 8831232/15840354   train_loss = 1150.532\n",
      "Epoch   0 Batch 9215232/15840354   train_loss = 1213.791\n",
      "Epoch   0 Batch 9599232/15840354   train_loss = 1065.347\n",
      "Epoch   0 Batch 9983232/15840354   train_loss = 1057.557\n",
      "Epoch   0 Batch 10367232/15840354   train_loss = 1211.268\n",
      "Epoch   0 Batch 10751232/15840354   train_loss = 997.641\n",
      "Epoch   0 Batch 11135232/15840354   train_loss = 1160.282\n",
      "Epoch   0 Batch 11519232/15840354   train_loss = 1151.050\n",
      "Epoch   0 Batch 11903232/15840354   train_loss = 1215.693\n",
      "Epoch   0 Batch 12287232/15840354   train_loss = 1336.303\n",
      "Epoch   0 Batch 12671232/15840354   train_loss = 1117.408\n",
      "Epoch   0 Batch 13055232/15840354   train_loss = 1151.402\n",
      "Epoch   0 Batch 13439232/15840354   train_loss = 1109.930\n",
      "Epoch   0 Batch 13823232/15840354   train_loss = 1158.422\n",
      "Epoch   0 Batch 14207232/15840354   train_loss = 1050.149\n",
      "Epoch   0 Batch 14591232/15840354   train_loss = 1090.457\n",
      "Epoch   0 Batch 14975232/15840354   train_loss = 1015.349\n",
      "Epoch   0 Batch 15359232/15840354   train_loss = 988.945\n",
      "Epoch   0 Batch 15743232/15840354   train_loss = 1047.940\n",
      "Epoch   0 Batch 383232/3960089   test_loss = 1145.522\n",
      "Epoch   0 Batch 767232/3960089   test_loss = 1076.361\n",
      "Epoch   0 Batch 1151232/3960089   test_loss = 1140.044\n",
      "Epoch   0 Batch 1535232/3960089   test_loss = 1104.411\n",
      "Epoch   0 Batch 1919232/3960089   test_loss = 1126.842\n",
      "Epoch   0 Batch 2303232/3960089   test_loss = 1144.797\n",
      "Epoch   0 Batch 2687232/3960089   test_loss = 1128.915\n",
      "Epoch   0 Batch 3071232/3960089   test_loss = 1204.310\n",
      "Epoch   0 Batch 3455232/3960089   test_loss = 1154.011\n",
      "Epoch   0 Batch 3839232/3960089   test_loss = 1185.716\n",
      "Epoch   1 Batch 286464/15840354   train_loss = 1070.575\n",
      "Epoch   1 Batch 670464/15840354   train_loss = 1090.746\n",
      "Epoch   1 Batch 1054464/15840354   train_loss = 1045.935\n",
      "Epoch   1 Batch 1438464/15840354   train_loss = 984.396\n",
      "Epoch   1 Batch 1822464/15840354   train_loss = 1028.170\n",
      "Epoch   1 Batch 2206464/15840354   train_loss = 1099.670\n",
      "Epoch   1 Batch 2590464/15840354   train_loss = 1079.372\n",
      "Epoch   1 Batch 2974464/15840354   train_loss = 1046.737\n",
      "Epoch   1 Batch 3358464/15840354   train_loss = 985.898\n",
      "Epoch   1 Batch 3742464/15840354   train_loss = 1108.574\n",
      "Epoch   1 Batch 4126464/15840354   train_loss = 983.600\n",
      "Epoch   1 Batch 4510464/15840354   train_loss = 1051.840\n",
      "Epoch   1 Batch 4894464/15840354   train_loss = 1077.671\n",
      "Epoch   1 Batch 5278464/15840354   train_loss = 875.621\n",
      "Epoch   1 Batch 5662464/15840354   train_loss = 1031.031\n",
      "Epoch   1 Batch 6046464/15840354   train_loss = 1059.949\n",
      "Epoch   1 Batch 6430464/15840354   train_loss = 1122.351\n",
      "Epoch   1 Batch 6814464/15840354   train_loss = 1097.492\n",
      "Epoch   1 Batch 7198464/15840354   train_loss = 1019.597\n",
      "Epoch   1 Batch 7582464/15840354   train_loss = 1043.061\n",
      "Epoch   1 Batch 7966464/15840354   train_loss = 1068.816\n",
      "Epoch   1 Batch 8350464/15840354   train_loss = 1147.392\n",
      "Epoch   1 Batch 8734464/15840354   train_loss = 1087.327\n",
      "Epoch   1 Batch 9118464/15840354   train_loss = 998.369\n",
      "Epoch   1 Batch 9502464/15840354   train_loss = 982.898\n",
      "Epoch   1 Batch 9886464/15840354   train_loss = 993.247\n",
      "Epoch   1 Batch 10270464/15840354   train_loss = 919.139\n",
      "Epoch   1 Batch 10654464/15840354   train_loss = 1088.294\n",
      "Epoch   1 Batch 11038464/15840354   train_loss = 1119.795\n",
      "Epoch   1 Batch 11422464/15840354   train_loss = 962.158\n",
      "Epoch   1 Batch 11806464/15840354   train_loss = 961.231\n",
      "Epoch   1 Batch 12190464/15840354   train_loss = 982.977\n",
      "Epoch   1 Batch 12574464/15840354   train_loss = 1056.352\n",
      "Epoch   1 Batch 12958464/15840354   train_loss = 1015.605\n",
      "Epoch   1 Batch 13342464/15840354   train_loss = 902.765\n",
      "Epoch   1 Batch 13726464/15840354   train_loss = 1038.509\n",
      "Epoch   1 Batch 14110464/15840354   train_loss = 1044.461\n",
      "Epoch   1 Batch 14494464/15840354   train_loss = 1012.639\n",
      "Epoch   1 Batch 14878464/15840354   train_loss = 1012.951\n",
      "Epoch   1 Batch 15262464/15840354   train_loss = 897.828\n",
      "Epoch   1 Batch 15646464/15840354   train_loss = 911.844\n",
      "Epoch   1 Batch 262656/3960089   test_loss = 1111.209\n",
      "Epoch   1 Batch 646656/3960089   test_loss = 1037.885\n",
      "Epoch   1 Batch 1030656/3960089   test_loss = 1107.239\n",
      "Epoch   1 Batch 1414656/3960089   test_loss = 1013.176\n",
      "Epoch   1 Batch 1798656/3960089   test_loss = 1089.915\n",
      "Epoch   1 Batch 2182656/3960089   test_loss = 1152.360\n",
      "Epoch   1 Batch 2566656/3960089   test_loss = 1001.656\n",
      "Epoch   1 Batch 2950656/3960089   test_loss = 1019.993\n",
      "Epoch   1 Batch 3334656/3960089   test_loss = 1039.148\n",
      "Epoch   1 Batch 3718656/3960089   test_loss = 976.070\n",
      "Epoch   2 Batch 189696/15840354   train_loss = 928.018\n",
      "Epoch   2 Batch 573696/15840354   train_loss = 1121.088\n",
      "Epoch   2 Batch 957696/15840354   train_loss = 902.438\n",
      "Epoch   2 Batch 1341696/15840354   train_loss = 962.111\n",
      "Epoch   2 Batch 1725696/15840354   train_loss = 923.596\n",
      "Epoch   2 Batch 2109696/15840354   train_loss = 1067.002\n",
      "Epoch   2 Batch 2493696/15840354   train_loss = 875.247\n",
      "Epoch   2 Batch 2877696/15840354   train_loss = 966.129\n",
      "Epoch   2 Batch 3261696/15840354   train_loss = 974.147\n",
      "Epoch   2 Batch 3645696/15840354   train_loss = 854.070\n",
      "Epoch   2 Batch 4029696/15840354   train_loss = 964.355\n",
      "Epoch   2 Batch 4413696/15840354   train_loss = 997.764\n",
      "Epoch   2 Batch 4797696/15840354   train_loss = 1005.183\n",
      "Epoch   2 Batch 5181696/15840354   train_loss = 934.436\n",
      "Epoch   2 Batch 5565696/15840354   train_loss = 898.362\n",
      "Epoch   2 Batch 5949696/15840354   train_loss = 919.067\n",
      "Epoch   2 Batch 6333696/15840354   train_loss = 978.355\n",
      "Epoch   2 Batch 6717696/15840354   train_loss = 969.636\n",
      "Epoch   2 Batch 7101696/15840354   train_loss = 981.242\n",
      "Epoch   2 Batch 7485696/15840354   train_loss = 889.268\n",
      "Epoch   2 Batch 7869696/15840354   train_loss = 978.068\n",
      "Epoch   2 Batch 8253696/15840354   train_loss = 1011.555\n",
      "Epoch   2 Batch 8637696/15840354   train_loss = 978.543\n",
      "Epoch   2 Batch 9021696/15840354   train_loss = 948.530\n",
      "Epoch   2 Batch 9405696/15840354   train_loss = 938.044\n",
      "Epoch   2 Batch 9789696/15840354   train_loss = 977.925\n",
      "Epoch   2 Batch 10173696/15840354   train_loss = 968.710\n",
      "Epoch   2 Batch 10557696/15840354   train_loss = 897.356\n",
      "Epoch   2 Batch 10941696/15840354   train_loss = 1000.839\n",
      "Epoch   2 Batch 11325696/15840354   train_loss = 902.554\n",
      "Epoch   2 Batch 11709696/15840354   train_loss = 918.579\n",
      "Epoch   2 Batch 12093696/15840354   train_loss = 918.723\n",
      "Epoch   2 Batch 12477696/15840354   train_loss = 883.318\n",
      "Epoch   2 Batch 12861696/15840354   train_loss = 889.297\n",
      "Epoch   2 Batch 13245696/15840354   train_loss = 858.394\n",
      "Epoch   2 Batch 13629696/15840354   train_loss = 874.771\n",
      "Epoch   2 Batch 14013696/15840354   train_loss = 916.262\n",
      "Epoch   2 Batch 14397696/15840354   train_loss = 898.224\n",
      "Epoch   2 Batch 14781696/15840354   train_loss = 873.065\n",
      "Epoch   2 Batch 15165696/15840354   train_loss = 890.967\n",
      "Epoch   2 Batch 15549696/15840354   train_loss = 850.303\n",
      "Epoch   2 Batch 142080/3960089   test_loss = 1076.970\n",
      "Epoch   2 Batch 526080/3960089   test_loss = 950.962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   2 Batch 910080/3960089   test_loss = 936.566\n",
      "Epoch   2 Batch 1294080/3960089   test_loss = 973.814\n",
      "Epoch   2 Batch 1678080/3960089   test_loss = 1047.216\n",
      "Epoch   2 Batch 2062080/3960089   test_loss = 936.333\n",
      "Epoch   2 Batch 2446080/3960089   test_loss = 1108.641\n",
      "Epoch   2 Batch 2830080/3960089   test_loss = 1024.219\n",
      "Epoch   2 Batch 3214080/3960089   test_loss = 1017.021\n",
      "Epoch   2 Batch 3598080/3960089   test_loss = 1116.570\n",
      "Epoch   3 Batch 92928/15840354   train_loss = 934.832\n",
      "Epoch   3 Batch 476928/15840354   train_loss = 911.011\n",
      "Epoch   3 Batch 860928/15840354   train_loss = 860.665\n",
      "Epoch   3 Batch 1244928/15840354   train_loss = 966.095\n",
      "Epoch   3 Batch 1628928/15840354   train_loss = 872.593\n",
      "Epoch   3 Batch 2012928/15840354   train_loss = 980.391\n",
      "Epoch   3 Batch 2396928/15840354   train_loss = 943.696\n",
      "Epoch   3 Batch 2780928/15840354   train_loss = 850.221\n",
      "Epoch   3 Batch 3164928/15840354   train_loss = 824.010\n",
      "Epoch   3 Batch 3548928/15840354   train_loss = 956.717\n",
      "Epoch   3 Batch 3932928/15840354   train_loss = 885.050\n",
      "Epoch   3 Batch 4316928/15840354   train_loss = 958.255\n",
      "Epoch   3 Batch 4700928/15840354   train_loss = 816.587\n",
      "Epoch   3 Batch 5084928/15840354   train_loss = 1011.479\n",
      "Epoch   3 Batch 5468928/15840354   train_loss = 1007.988\n",
      "Epoch   3 Batch 5852928/15840354   train_loss = 1035.705\n",
      "Epoch   3 Batch 6236928/15840354   train_loss = 999.689\n",
      "Epoch   3 Batch 6620928/15840354   train_loss = 968.604\n",
      "Epoch   3 Batch 7004928/15840354   train_loss = 978.210\n",
      "Epoch   3 Batch 7388928/15840354   train_loss = 828.829\n",
      "Epoch   3 Batch 7772928/15840354   train_loss = 770.154\n",
      "Epoch   3 Batch 8156928/15840354   train_loss = 870.931\n",
      "Epoch   3 Batch 8540928/15840354   train_loss = 1125.431\n",
      "Epoch   3 Batch 8924928/15840354   train_loss = 855.037\n",
      "Epoch   3 Batch 9308928/15840354   train_loss = 1006.796\n",
      "Epoch   3 Batch 9692928/15840354   train_loss = 1006.462\n",
      "Epoch   3 Batch 10076928/15840354   train_loss = 958.981\n",
      "Epoch   3 Batch 10460928/15840354   train_loss = 878.615\n",
      "Epoch   3 Batch 10844928/15840354   train_loss = 824.527\n",
      "Epoch   3 Batch 11228928/15840354   train_loss = 901.134\n",
      "Epoch   3 Batch 11612928/15840354   train_loss = 910.480\n",
      "Epoch   3 Batch 11996928/15840354   train_loss = 955.050\n",
      "Epoch   3 Batch 12380928/15840354   train_loss = 828.511\n",
      "Epoch   3 Batch 12764928/15840354   train_loss = 912.371\n",
      "Epoch   3 Batch 13148928/15840354   train_loss = 933.121\n",
      "Epoch   3 Batch 13532928/15840354   train_loss = 848.987\n",
      "Epoch   3 Batch 13916928/15840354   train_loss = 935.045\n",
      "Epoch   3 Batch 14300928/15840354   train_loss = 902.346\n",
      "Epoch   3 Batch 14684928/15840354   train_loss = 966.608\n",
      "Epoch   3 Batch 15068928/15840354   train_loss = 946.324\n",
      "Epoch   3 Batch 15452928/15840354   train_loss = 874.987\n",
      "Epoch   3 Batch 15836928/15840354   train_loss = 917.998\n",
      "Epoch   3 Batch 21504/3960089   test_loss = 1083.402\n",
      "Epoch   3 Batch 405504/3960089   test_loss = 1059.958\n",
      "Epoch   3 Batch 789504/3960089   test_loss = 1155.366\n",
      "Epoch   3 Batch 1173504/3960089   test_loss = 1058.622\n",
      "Epoch   3 Batch 1557504/3960089   test_loss = 1065.520\n",
      "Epoch   3 Batch 1941504/3960089   test_loss = 1114.044\n",
      "Epoch   3 Batch 2325504/3960089   test_loss = 1111.363\n",
      "Epoch   3 Batch 2709504/3960089   test_loss = 1143.636\n",
      "Epoch   3 Batch 3093504/3960089   test_loss = 1129.634\n",
      "Epoch   3 Batch 3477504/3960089   test_loss = 1092.305\n",
      "Epoch   3 Batch 3861504/3960089   test_loss = 1024.157\n",
      "Epoch   4 Batch 380160/15840354   train_loss = 965.114\n",
      "Epoch   4 Batch 764160/15840354   train_loss = 1017.299\n",
      "Epoch   4 Batch 1148160/15840354   train_loss = 952.829\n",
      "Epoch   4 Batch 1532160/15840354   train_loss = 950.791\n",
      "Epoch   4 Batch 1916160/15840354   train_loss = 853.589\n",
      "Epoch   4 Batch 2300160/15840354   train_loss = 886.958\n",
      "Epoch   4 Batch 2684160/15840354   train_loss = 987.699\n",
      "Epoch   4 Batch 3068160/15840354   train_loss = 930.491\n",
      "Epoch   4 Batch 3452160/15840354   train_loss = 979.728\n",
      "Epoch   4 Batch 3836160/15840354   train_loss = 848.824\n",
      "Epoch   4 Batch 4220160/15840354   train_loss = 1127.610\n",
      "Epoch   4 Batch 4604160/15840354   train_loss = 867.927\n",
      "Epoch   4 Batch 4988160/15840354   train_loss = 827.938\n",
      "Epoch   4 Batch 5372160/15840354   train_loss = 1086.518\n",
      "Epoch   4 Batch 5756160/15840354   train_loss = 1052.469\n",
      "Epoch   4 Batch 6140160/15840354   train_loss = 1080.083\n",
      "Epoch   4 Batch 6524160/15840354   train_loss = 998.779\n",
      "Epoch   4 Batch 6908160/15840354   train_loss = 929.066\n",
      "Epoch   4 Batch 7292160/15840354   train_loss = 907.103\n",
      "Epoch   4 Batch 7676160/15840354   train_loss = 936.041\n",
      "Epoch   4 Batch 8060160/15840354   train_loss = 858.393\n",
      "Epoch   4 Batch 8444160/15840354   train_loss = 858.074\n",
      "Epoch   4 Batch 8828160/15840354   train_loss = 779.687\n",
      "Epoch   4 Batch 9212160/15840354   train_loss = 962.690\n",
      "Epoch   4 Batch 9596160/15840354   train_loss = 925.874\n",
      "Epoch   4 Batch 9980160/15840354   train_loss = 917.343\n",
      "Epoch   4 Batch 10364160/15840354   train_loss = 974.191\n",
      "Epoch   4 Batch 10748160/15840354   train_loss = 823.640\n",
      "Epoch   4 Batch 11132160/15840354   train_loss = 1060.727\n",
      "Epoch   4 Batch 11516160/15840354   train_loss = 865.525\n",
      "Epoch   4 Batch 11900160/15840354   train_loss = 854.693\n",
      "Epoch   4 Batch 12284160/15840354   train_loss = 837.497\n",
      "Epoch   4 Batch 12668160/15840354   train_loss = 841.338\n",
      "Epoch   4 Batch 13052160/15840354   train_loss = 748.417\n",
      "Epoch   4 Batch 13436160/15840354   train_loss = 922.983\n",
      "Epoch   4 Batch 13820160/15840354   train_loss = 999.578\n",
      "Epoch   4 Batch 14204160/15840354   train_loss = 988.102\n",
      "Epoch   4 Batch 14588160/15840354   train_loss = 869.200\n",
      "Epoch   4 Batch 14972160/15840354   train_loss = 999.928\n",
      "Epoch   4 Batch 15356160/15840354   train_loss = 835.379\n",
      "Epoch   4 Batch 15740160/15840354   train_loss = 1001.083\n",
      "Epoch   4 Batch 284928/3960089   test_loss = 1144.121\n",
      "Epoch   4 Batch 668928/3960089   test_loss = 1093.166\n",
      "Epoch   4 Batch 1052928/3960089   test_loss = 1060.180\n",
      "Epoch   4 Batch 1436928/3960089   test_loss = 1284.248\n",
      "Epoch   4 Batch 1820928/3960089   test_loss = 1299.865\n",
      "Epoch   4 Batch 2204928/3960089   test_loss = 1179.312\n",
      "Epoch   4 Batch 2588928/3960089   test_loss = 1125.823\n",
      "Epoch   4 Batch 2972928/3960089   test_loss = 1287.933\n",
      "Epoch   4 Batch 3356928/3960089   test_loss = 1175.862\n",
      "Epoch   4 Batch 3740928/3960089   test_loss = 1134.877\n",
      "Epoch   5 Batch 283392/15840354   train_loss = 885.088\n",
      "Epoch   5 Batch 667392/15840354   train_loss = 855.111\n",
      "Epoch   5 Batch 1051392/15840354   train_loss = 929.512\n",
      "Epoch   5 Batch 1435392/15840354   train_loss = 841.103\n",
      "Epoch   5 Batch 1819392/15840354   train_loss = 880.841\n",
      "Epoch   5 Batch 2203392/15840354   train_loss = 819.857\n",
      "Epoch   5 Batch 2587392/15840354   train_loss = 801.555\n",
      "Epoch   5 Batch 2971392/15840354   train_loss = 1218.335\n",
      "Epoch   5 Batch 3355392/15840354   train_loss = 778.064\n",
      "Epoch   5 Batch 3739392/15840354   train_loss = 1027.707\n",
      "Epoch   5 Batch 4123392/15840354   train_loss = 946.059\n",
      "Epoch   5 Batch 4507392/15840354   train_loss = 949.982\n",
      "Epoch   5 Batch 4891392/15840354   train_loss = 935.233\n",
      "Epoch   5 Batch 5275392/15840354   train_loss = 818.169\n",
      "Epoch   5 Batch 5659392/15840354   train_loss = 876.774\n",
      "Epoch   5 Batch 6043392/15840354   train_loss = 882.122\n",
      "Epoch   5 Batch 6427392/15840354   train_loss = 1034.831\n",
      "Epoch   5 Batch 6811392/15840354   train_loss = 836.312\n",
      "Epoch   5 Batch 7195392/15840354   train_loss = 806.242\n",
      "Epoch   5 Batch 7579392/15840354   train_loss = 880.072\n",
      "Epoch   5 Batch 7963392/15840354   train_loss = 1049.266\n",
      "Epoch   5 Batch 8347392/15840354   train_loss = 792.450\n",
      "Epoch   5 Batch 8731392/15840354   train_loss = 800.338\n",
      "Epoch   5 Batch 9115392/15840354   train_loss = 958.124\n",
      "Epoch   5 Batch 9499392/15840354   train_loss = 881.903\n",
      "Epoch   5 Batch 9883392/15840354   train_loss = 1028.189\n",
      "Epoch   5 Batch 10267392/15840354   train_loss = 828.915\n",
      "Epoch   5 Batch 10651392/15840354   train_loss = 922.123\n",
      "Epoch   5 Batch 11035392/15840354   train_loss = 873.258\n",
      "Epoch   5 Batch 11419392/15840354   train_loss = 884.606\n",
      "Epoch   5 Batch 11803392/15840354   train_loss = 965.838\n",
      "Epoch   5 Batch 12187392/15840354   train_loss = 801.924\n",
      "Epoch   5 Batch 12571392/15840354   train_loss = 1012.814\n",
      "Epoch   5 Batch 12955392/15840354   train_loss = 960.659\n",
      "Epoch   5 Batch 13339392/15840354   train_loss = 801.359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   5 Batch 13723392/15840354   train_loss = 895.212\n",
      "Epoch   5 Batch 14107392/15840354   train_loss = 951.245\n",
      "Epoch   5 Batch 14491392/15840354   train_loss = 850.574\n",
      "Epoch   5 Batch 14875392/15840354   train_loss = 738.348\n",
      "Epoch   5 Batch 15259392/15840354   train_loss = 841.624\n",
      "Epoch   5 Batch 15643392/15840354   train_loss = 844.419\n",
      "Epoch   5 Batch 164352/3960089   test_loss = 1144.722\n",
      "Epoch   5 Batch 548352/3960089   test_loss = 1092.105\n",
      "Epoch   5 Batch 932352/3960089   test_loss = 1323.005\n",
      "Epoch   5 Batch 1316352/3960089   test_loss = 1199.119\n",
      "Epoch   5 Batch 1700352/3960089   test_loss = 1199.100\n",
      "Epoch   5 Batch 2084352/3960089   test_loss = 1233.202\n",
      "Epoch   5 Batch 2468352/3960089   test_loss = 1113.564\n",
      "Epoch   5 Batch 2852352/3960089   test_loss = 1134.825\n",
      "Epoch   5 Batch 3236352/3960089   test_loss = 1235.720\n",
      "Epoch   5 Batch 3620352/3960089   test_loss = 1093.614\n"
     ]
    }
   ],
   "source": [
    "len_train_features = len(train_features)\n",
    "index = 0\n",
    "model = Verify_Assumption_Model()\n",
    "model.cuda()\n",
    "\n",
    "loss_fn = torch.nn.MSELoss(reduce=False, size_average=False)\n",
    "opt = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                               lr=lr, weight_decay=0)\n",
    "losses = {'train':[], 'test':[]}\n",
    "\n",
    "for epoch_i in range(Epoch):\n",
    "    index = 0\n",
    "    while index <= len_train_features:\n",
    "        index_end = index + batch_size\n",
    "        if index_end >= len_train_features:\n",
    "            batch_train = train_features[index:len_train_features]\n",
    "            batch_train_target = train_target[index:len_train_features]\n",
    "        else:\n",
    "            batch_train = train_features[index:index_end]\n",
    "            batch_train_target = train_target[index:index_end]\n",
    "\n",
    "        #assert len(batch_train) == len(batch_train_target)\n",
    "\n",
    "        userId = batch_train[:,0]\n",
    "        movieId = batch_train[:,1]\n",
    "        movie_vec = []\n",
    "        for i in range(len(movieId)):\n",
    "            movie_vec.append(genome_scores_dict[str(movieId[i])])\n",
    "\n",
    "\n",
    "        rating = model(torch.tensor(userId, requires_grad = False).cuda(),torch.tensor(movie_vec, requires_grad = False).cuda())\n",
    "        rating = rating.squeeze_(1).squeeze_(1)\n",
    "        loss = sum(loss_fn(rating,torch.tensor(batch_train_target,dtype=torch.float32,requires_grad = False).cuda()))\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        losses['train'].append(loss.detach().cpu().numpy())\n",
    "        opt.step()\n",
    "        if len(losses['train']) % 500 == 0:\n",
    "            print('Epoch {:>3} Batch {:>4}/15840354   train_loss = {:.3f}'.format(\n",
    "                        epoch_i,\n",
    "                        index,\n",
    "                        losses['train'][len(losses['train'])-1]))\n",
    "        index += batch_size\n",
    "        \n",
    "    #############################test#############################\n",
    "    \n",
    "    len_test_features = len(test_features)\n",
    "    index = 0\n",
    "\n",
    "    while index <= len_test_features:\n",
    "        index_end = index + batch_size\n",
    "        if index_end >= len_train_features:\n",
    "            batch_train = test_features[index:len_train_features]\n",
    "            batch_train_target = test_target[index:len_train_features]\n",
    "        else:\n",
    "            batch_train = test_features[index:index_end]\n",
    "            batch_train_target = test_target[index:index_end]\n",
    "\n",
    "        #assert len(batch_train) == len(batch_train_target)\n",
    "\n",
    "        userId = batch_train[:,0]\n",
    "        movieId = batch_train[:,1]\n",
    "        movie_vec = []\n",
    "        for i in range(len(movieId)):\n",
    "            movie_vec.append(genome_scores_dict[str(movieId[i])])\n",
    "\n",
    "\n",
    "        rating = model(torch.tensor(userId, requires_grad = False).cuda(),torch.tensor(movie_vec, requires_grad = False).cuda())\n",
    "        rating = rating.squeeze_(1).squeeze_(1)\n",
    "        loss = sum(loss_fn(rating,torch.tensor(batch_train_target,dtype=torch.float32,requires_grad = False).cuda()))\n",
    "\n",
    "        losses['test'].append(loss.detach().cpu().numpy())\n",
    "        if len(losses['test']) % 500 == 0:\n",
    "            print('Epoch {:>3} Batch {:>4}/3960089   test_loss = {:.3f}'.format(\n",
    "                        epoch_i,\n",
    "                        index,\n",
    "                        losses['test'][len(losses['test'])-1]))\n",
    "        index += batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses['train'], label='Training loss')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses['test'], label='test loss')\n",
    "plt.legend()\n",
    "_ = plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to './data/model.pt'\n",
    "torch.save(model.state_dict(), './data/model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model from state_dict file './data/model.pt'\n",
    "model = Verify_Assumption_Model()\n",
    "model.load_state_dict(torch.load('./data/model.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Result Analysis and Evaluation\n",
    "&ensp;&ensp;We can see the test loss slowly descend first and then rise slowly. I think we get a better result by changing the parameters. However, because the training time is too long, there is not enough time to modify different parameters for experiment. I may do it later.  \n",
    "&ensp;&ensp;Compared with other people's results, such as [chengstone/movie_recommender](https://github.com/chengstone/movie_recommender \"With a Title\") based on [ml-1m](https://grouplens.org/datasets/movielens/1m/ \"With a Title\"), our test loss is close. His loss is mean(loss) and here is sum(loss). mean(loss) = sum(loss)/batch_size.  \n",
    "&ensp;&ensp;So, the performance of this model is good, and it can help us to verify the assumption: relevance vector can represent movies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Recommend System\n",
    "Based on the model in chapter 4, we can build a recommend system that can:  \n",
    "&ensp;1) Give a list of movies related to a movie;  \n",
    "&ensp;2) Predict user favourite movies;  \n",
    "&ensp;3) Recommend relevant movies that user would like and that user have just watched."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Give relevant movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_movies(id, orginal=True, movie_num=10):\n",
    "    \n",
    "    movie_feature = []\n",
    "    movie_id = []\n",
    "    movie_num += 1 # because the most relevant movie is the same movie.\n",
    "    \n",
    "    # Get all movie vector, You can run quickly if you save the movie vector in your memory.\n",
    "    for key in genome_scores_dict.keys():\n",
    "        movie_id.append(key)\n",
    "        if orginal:     \n",
    "            norm = np.linalg.norm(genome_scores_dict[key],ord=2) \n",
    "            movie_feature.append(genome_scores_dict[key]/norm)\n",
    "        else:\n",
    "            v = model.movie_transfrom(torch.tensor(genome_scores_dict[key]).cuda()).cpu().detach().numpy()\n",
    "            norm = np.linalg.norm(v,ord=2) \n",
    "            movie_feature.append(v/norm)\n",
    "\n",
    "    movie_feature = torch.tensor(movie_feature).unsqueeze_(1).cuda()\n",
    "\n",
    "    if orginal: \n",
    "        norm = np.linalg.norm(genome_scores_dict[str(id)],ord=2)\n",
    "        in_movie = torch.tensor(genome_scores_dict[str(id)]/norm).expand(10381, 1128).unsqueeze_(2).cuda()\n",
    "    else:\n",
    "        v = model.movie_transfrom(torch.tensor(genome_scores_dict[str(id)]).cuda()).cpu().detach().numpy()\n",
    "        norm = np.linalg.norm(v,ord=2)\n",
    "        in_movie = torch.tensor(v/norm).cuda().expand(10381, 512).unsqueeze_(2)\n",
    "    \n",
    "    similarity = torch.bmm(movie_feature,in_movie).squeeze_(1).squeeze_(1).cpu().detach().numpy()\n",
    "    index = np.argpartition(similarity, -movie_num)[-movie_num:]\n",
    "    \n",
    "    if orginal: \n",
    "        print('Find relevant movies based on relevance vector from genome-scores.csv')\n",
    "    else:\n",
    "        print('Find relevant movies based on movie feature vector from training model')\n",
    "    \n",
    "    print('')\n",
    "    print('Input Movie: {}'.format(movies[movies['movieId']==id].values[0]))\n",
    "    print('')\n",
    "    print('Relevant Movie:')\n",
    "    \n",
    "    re = []\n",
    "    for i in index:\n",
    "        if movie_id[i] != str(id):\n",
    "            print('    {}'.format(movies[movies['movieId']==int(movie_id[i])].values[0]))\n",
    "            re.append(movie_id[i])\n",
    "            \n",
    "    return re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis the result on next code cell\n",
    "&ensp;&ensp;Here we present the relevant movie search based on the machine learning model and relevance vector from `genome_scores.csv`. We find that both methods can find relevant movies, and there is a certain overlap between the two methods. I think the movie feature vector from model is close to the relevance vector from `genome_scores.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find relevant movies based on relevance vector from genome-scores.csv\n",
      "\n",
      "Input Movie: [2 'Jumanji (1995)' 'Adventure|Children|Fantasy']\n",
      "\n",
      "Relevant Movie:\n",
      "    [2047 'Gnome-Mobile, The (1967)' 'Adventure|Children|Fantasy|Musical']\n",
      "    [1920 'Small Soldiers (1998)' 'Animation|Children|Fantasy|War']\n",
      "    [480 'Jurassic Park (1993)' 'Action|Adventure|Sci-Fi|Thriller']\n",
      "    [7781 'Twister (1990)' 'Comedy']\n",
      "    [455 'Free Willy (1993)' 'Adventure|Children|Drama']\n",
      "    [40851 'Zathura (2005)' 'Action|Adventure|Children|Fantasy']\n",
      "    [2429 'Mighty Joe Young (1998)' 'Action|Adventure|Drama|Fantasy|Thriller']\n",
      "    [46972 'Night at the Museum (2006)' 'Action|Comedy|Fantasy|IMAX']\n",
      "    [2054 'Honey, I Shrunk the Kids (1989)'\n",
      " 'Adventure|Children|Comedy|Fantasy|Sci-Fi']\n",
      "    [1848 'Borrowers, The (1997)' 'Adventure|Children|Comedy|Fantasy']\n",
      "\n",
      "--------------------------------\n",
      "\n",
      "Find relevant movies based on movie feature vector from training model\n",
      "\n",
      "Input Movie: [2 'Jumanji (1995)' 'Adventure|Children|Fantasy']\n",
      "\n",
      "Relevant Movie:\n",
      "    [50162 'Arthur and the Invisibles (2007)' 'Action|Children|Fantasy']\n",
      "    [3784 'Kid, The (2000)' 'Comedy|Fantasy']\n",
      "    [7781 'Twister (1990)' 'Comedy']\n",
      "    [7019 'Project X (1987)' 'Comedy|Drama']\n",
      "    [2429 'Mighty Joe Young (1998)' 'Action|Adventure|Drama|Fantasy|Thriller']\n",
      "    [40851 'Zathura (2005)' 'Action|Adventure|Children|Fantasy']\n",
      "    [65088 'Bedtime Stories (2008)' 'Adventure|Children|Comedy']\n",
      "    [46972 'Night at the Museum (2006)' 'Action|Comedy|Fantasy|IMAX']\n",
      "    [119155 'Night at the Museum: Secret of the Tomb (2014)'\n",
      " 'Adventure|Children|Comedy|Fantasy']\n",
      "    [2054 'Honey, I Shrunk the Kids (1989)'\n",
      " 'Adventure|Children|Comedy|Fantasy|Sci-Fi']\n"
     ]
    }
   ],
   "source": [
    "get_relevant_movies(2,True)\n",
    "print('')\n",
    "print('--------------------------------')\n",
    "print('')\n",
    "get_relevant_movies(2,False)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Predict User Favourite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_your_favourite(userId, movie_num=10):\n",
    "    \n",
    "    user_vector = model.emb_user(torch.tensor([userId]).cuda()).expand(10381, 512).unsqueeze_(2).cuda()\n",
    "    \n",
    "    movie_feature = []\n",
    "    movie_id = []\n",
    "    for key in genome_scores_dict.keys():\n",
    "        movie_id.append(key)\n",
    "        movie_feature.append(model.movie_transfrom(torch.tensor(genome_scores_dict[key]).cuda()).cpu().detach().numpy())\n",
    "\n",
    "    movie_feature = torch.tensor(movie_feature).unsqueeze_(1).cuda()\n",
    "\n",
    "    favourite_v = torch.bmm(movie_feature,user_vector).squeeze_(1).squeeze_(1).cpu().detach().numpy()\n",
    "    index = np.argpartition(favourite_v, -movie_num)[-movie_num:]\n",
    "    \n",
    "    \n",
    "    print('Find your top{} favourite movies'.format(movie_num))\n",
    "    \n",
    "    print('')\n",
    "    print('Favourite Movie:')\n",
    "    \n",
    "    re = []\n",
    "    for i in index:\n",
    "        if movie_id[i] != str(id):\n",
    "            print('    {}'.format(movies[movies['movieId']==int(movie_id[i])].values[0]))\n",
    "            re.append(movie_id[i])\n",
    "            \n",
    "    print('')\n",
    "    print('The rating of these movies by user {}'.format(userId))\n",
    "    \n",
    "    for i in re:\n",
    "        result = ratings[(ratings['movieId']==int(i))&(ratings['userId']==userId)].values\n",
    "        if len(result) > 0:\n",
    "            print('    Movie ({:>5}). Rating: {}'.format(i, result[0][2]))\n",
    "        else:\n",
    "            print('    There is no rating on this movie ({:>6}) by user.'.format(i))\n",
    "    return re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis the result on next code cell\n",
    "&ensp;&ensp;Looking for the user's favorite movies does not require that users have commented on them. So there will be some movies that have no been rated by this user and some other movies with a relative high scores rated by this user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Find your top10 favourite movies\n",
      "\n",
      "Favourite Movie:\n",
      "    [5952 'Lord of the Rings: The Two Towers, The (2002)' 'Adventure|Fantasy']\n",
      "    [260 'Star Wars: Episode IV - A New Hope (1977)' 'Action|Adventure|Sci-Fi']\n",
      "    [1196 'Star Wars: Episode V - The Empire Strikes Back (1980)'\n",
      " 'Action|Adventure|Sci-Fi']\n",
      "    [1200 'Aliens (1986)' 'Action|Adventure|Horror|Sci-Fi']\n",
      "    [1210 'Star Wars: Episode VI - Return of the Jedi (1983)'\n",
      " 'Action|Adventure|Sci-Fi']\n",
      "    [1214 'Alien (1979)' 'Horror|Sci-Fi']\n",
      "    [109487 'Interstellar (2014)' 'Sci-Fi|IMAX']\n",
      "    [104841 'Gravity (2013)' 'Action|Sci-Fi|IMAX']\n",
      "    [79132 'Inception (2010)'\n",
      " 'Action|Crime|Drama|Mystery|Sci-Fi|Thriller|IMAX']\n",
      "    [2571 'Matrix, The (1999)' 'Action|Sci-Fi|Thriller']\n",
      "\n",
      "The rating of these movies by user 7\n",
      "    There is no rating on this movie (  5952) by user.\n",
      "    Movie (  260). Rating: 5.0\n",
      "    Movie ( 1196). Rating: 5.0\n",
      "    There is no rating on this movie (  1200) by user.\n",
      "    Movie ( 1210). Rating: 5.0\n",
      "    There is no rating on this movie (  1214) by user.\n",
      "    There is no rating on this movie (109487) by user.\n",
      "    There is no rating on this movie (104841) by user.\n",
      "    There is no rating on this movie ( 79132) by user.\n",
      "    There is no rating on this movie (  2571) by user.\n"
     ]
    }
   ],
   "source": [
    "guess_your_favourite(7)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Recommend Movie to User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommand_relevant_movies_you_may_like(movieId, userId, movie_num=5):\n",
    "    \n",
    "    # The first part code copy from get_relevant_movies\n",
    "    \n",
    "    movie_feature = []\n",
    "    movie_id = []\n",
    "    \n",
    "    # Get all movie vector, You can run quickly if you save the movie vector in your memory.\n",
    "    for key in genome_scores_dict.keys():\n",
    "        movie_id.append(key)\n",
    "        norm = np.linalg.norm(genome_scores_dict[key],ord=2) \n",
    "        movie_feature.append(genome_scores_dict[key]/norm)\n",
    "\n",
    "    movie_feature = torch.tensor(movie_feature).unsqueeze_(1).cuda()\n",
    " \n",
    "    norm = np.linalg.norm(genome_scores_dict[str(movieId)],ord=2)\n",
    "    in_movie = torch.tensor(genome_scores_dict[str(movieId)]/norm).expand(10381, 1128).unsqueeze_(2).cuda()\n",
    "    \n",
    "    similarity = torch.bmm(movie_feature,in_movie).squeeze_(1).squeeze_(1).cpu().detach().numpy()\n",
    "    index = np.argpartition(similarity, -51)[-51:]\n",
    "    \n",
    "    re = []\n",
    "    \n",
    "    # The Second part code copy from guess_your_favourite\n",
    "            \n",
    "    user_vector = model.emb_user(torch.tensor([userId]).cuda()).expand(50, 512).unsqueeze_(2).cuda()\n",
    "    \n",
    "    movie_feature = []\n",
    "    movie_id2 = []\n",
    "    \n",
    "    for i in index:\n",
    "        if movie_id[i] != str(movieId):\n",
    "            movie_id2.append(movie_id[i])\n",
    "            movie_feature.append(model.movie_transfrom(torch.tensor(genome_scores_dict[movie_id[i]]).cuda()).cpu().detach().numpy())\n",
    "            \n",
    "    movie_feature = torch.tensor(movie_feature).unsqueeze_(1).cuda()\n",
    "\n",
    "    favourite_v = torch.bmm(movie_feature,user_vector).squeeze_(1).squeeze_(1).cpu().detach().numpy()\n",
    "    index = np.argpartition(favourite_v, -movie_num)[-movie_num:]\n",
    "    \n",
    "    print('Input Movie: {}'.format(movies[movies['movieId']==movieId].values[0]))\n",
    "    print('User {} may like these {} relevant movies: '.format(userId, movie_num))\n",
    "    \n",
    "    print('')\n",
    "    print('Recommand List:')\n",
    "    \n",
    "    re = []\n",
    "    for i in index:\n",
    "        if movie_id2[i] != str(id):\n",
    "            print('    {}'.format(movies[movies['movieId']==int(movie_id2[i])].values[0]))\n",
    "            re.append(movie_id2[i])\n",
    "            \n",
    "    print('')\n",
    "    print('The rating of these movies by user {}: '.format(userId))\n",
    "    \n",
    "    for i in re:\n",
    "        result = ratings[(ratings['movieId']==int(i))&(ratings['userId']==userId)].values\n",
    "        if len(result) > 0:\n",
    "            print('    Movie ({:>3}). Rating: {}'.format(i, result[0][2]))\n",
    "        else:\n",
    "            print('    There is no rating on this movie ({:>5}) by user.'.format(i))\n",
    "            \n",
    "    return re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis the result on next code cell\n",
    "1. we can find that the recommended movies are similar to the input movie.  \n",
    "2. the recommended movies are not exactly the same as the chapter 5.1 and chapter 5.2. The result of chapter 5.1 base on movie id = 2 and the result of chapter 5.2 base on user id = 7. The result here base on movie id = 2 and user id = 7.  \n",
    "3. The rating of the recommended movies are relative high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Movie: [2 'Jumanji (1995)' 'Adventure|Children|Fantasy']\n",
      "User 7 may like these 5 relevant movies: \n",
      "\n",
      "Recommand List:\n",
      "    [653 'Dragonheart (1996)' 'Action|Adventure|Fantasy']\n",
      "    [480 'Jurassic Park (1993)' 'Action|Adventure|Sci-Fi|Thriller']\n",
      "    [2617 'Mummy, The (1999)'\n",
      " 'Action|Adventure|Comedy|Fantasy|Horror|Thriller']\n",
      "    [40851 'Zathura (2005)' 'Action|Adventure|Children|Fantasy']\n",
      "    [736 'Twister (1996)' 'Action|Adventure|Romance|Thriller']\n",
      "\n",
      "The rating of these movies by user 7: \n",
      "    There is no rating on this movie (  653) by user.\n",
      "    Movie (480). Rating: 5.0\n",
      "    There is no rating on this movie ( 2617) by user.\n",
      "    There is no rating on this movie (40851) by user.\n",
      "    Movie (736). Rating: 3.0\n"
     ]
    }
   ],
   "source": [
    "recommand_relevant_movies_you_may_like(2, 7, movie_num=5)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Shortcoming and Future Work\n",
    "&ensp;&ensp;If use relevance vector from `genome_scores.csv` represent movies, we need more relevance vector since there are only 53.0% movies in the dataset with a relevance vector. So, I think in the future, we can do the following work:  \n",
    "&ensp;&ensp;&ensp;1) Build a model predit relevance vector for moives. It can be a machine learning model or others such as the [orginal model](http://files.grouplens.org/papers/tag_genome.pdf \"With a title\").  \n",
    "&ensp;&ensp;&ensp;2) Predicting user ratings may not be the best way to implement recommendation system. We should try other methods.  \n",
    "&ensp;&ensp;&ensp;3) Relevance vector may not be the best way to represent a movies. We should also try other methods.  \n",
    "&ensp;&ensp;&ensp;4) Get more data from internet through `link.csv` to build a model considering the whole reviews from the users.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch]",
   "language": "python",
   "name": "conda-env-torch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
